{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "# Importing BeautifulSoup class from the bs4 module\n",
    "from bs4 import BeautifulSoup\n",
    "# Importing the HTTP library\n",
    "import requests as req\n",
    "from tqdm import tqdm\n",
    "#from extract import filename \n",
    "import os "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TXT OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign values to the desired column\n",
    "df = pd.DataFrame({'Key word': [\"scope 1\", \"scope one\", \"scope 2\", \"scope two\", \"scope 3\", \"scope three\",\n",
    "                                 \"emissions\", \"GHG emissions\", \"GHG\", \"carbon emissions\", \"carbon\"]})\n",
    "\n",
    "\n",
    "# Write the updated DataFrame back to the CSV file\n",
    "df.to_csv('source.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the CSV file as a pandas DataFrame\n",
    "data = pd.read_csv('source.csv')\n",
    "# Specify the CSV file name and column name\n",
    "column_name = 'Frequency'\n",
    "key_word = data['Key word']\n",
    "for i in range(len(key_word)):\n",
    "    with open('sample2.txt', 'r') as fp:\n",
    "        lines = fp.readlines()\n",
    "        string = key_word[i]\n",
    "        for line in lines:\n",
    "            if line.find(string) != -1:\n",
    "                print(string)\n",
    "                data.loc[i, column_name] += 1 \n",
    "                data.to_csv('source.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the dict structure for hierarchy\n",
    "key_word = data['Key Word']\n",
    "freq = data['Frequency']\n",
    "tuples = zip(key_word, freq)\n",
    "d = dict(tuples)\n",
    "print(d)\n",
    "\n",
    "# remaining 1.match the corresponding source paper using token number \n",
    "#           2.parallel testing  \n",
    "#           3.given the hierarchy, optimize the searching results with higher accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXCEL OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Description _x000D_   FY21 _x000D_  \\\n",
      "0                                    Scope 1 _x000D_   2.6^ _x000D_   \n",
      "1  GHG emissions (Scope 1&2) by facility type (MT...   13.3 _x000D_   \n",
      "2                            Scope 2 (MBM)53 _x000D_  11.7^ _x000D_   \n",
      "3                                    Scope 2 _x000D_   99.0 _x000D_   \n",
      "4                                    Scope 3 _x000D_  10.1^ _x000D_   \n",
      "5                               Scope 3 FERA _x000D_   34.4 _x000D_   \n",
      "\n",
      "    FY20 _x000D_   FY19 _x000D_    GRI _x000D_ SASB _x000D_ UNGC _x000D_  \\\n",
      "0   3.0^ _x000D_   6.5^ _x000D_  305-1 _x000D_          NaN          NaN   \n",
      "1   24.5 _x000D_   53.1 _x000D_            NaN          NaN          NaN   \n",
      "2  22.1^ _x000D_  46.6^ _x000D_  305-2 _x000D_          NaN          NaN   \n",
      "3  108.6 _x000D_   99.0 _x000D_  305-2 _x000D_          NaN          NaN   \n",
      "4  13.6^ _x000D_  59.6^ _x000D_  305-3 _x000D_          NaN          NaN   \n",
      "5      – _x000D_      – _x000D_  305-3 _x000D_          NaN          NaN   \n",
      "\n",
      "             SCM _x000D_  \n",
      "0                    NaN  \n",
      "1  GHG emissions _x000D_  \n",
      "2                    NaN  \n",
      "3                    NaN  \n",
      "4                    NaN  \n",
      "5                    NaN  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_excel('fileoutpart0.xlsx')\n",
    "key_list = ['Scope 1','Scope 2','Scope 3']\n",
    "# df.to_csv('fileoutpart0.csv', index=False)\n",
    "# Find the rows that contain each keyword\n",
    "rows_with_keywords = pd.DataFrame(columns=df.columns)\n",
    "for keyword in key_list:\n",
    "    temp_rows = df[df.apply(lambda row: row.astype(str).str.contains(keyword).any(), axis=1)]\n",
    "    rows_with_keywords = pd.concat([rows_with_keywords, temp_rows], ignore_index=True)\n",
    "\n",
    "# Remove duplicate rows\n",
    "rows_with_keywords.drop_duplicates(inplace=True)\n",
    "\n",
    "# Print the rows that contain the keywords\n",
    "print(rows_with_keywords)\n",
    "\n",
    "# Output the rows that contain the keywords to a new Excel file\n",
    "rows_with_keywords.to_excel('xlsx_output.xlsx', index=False)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Json Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [{'boxes': {'CropBox': [0, 0, 1044, 612], 'Med...\n",
       "Name: pages, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('structuredData.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "df = pd.json_normalize(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_list = ['Scope 1','Scope 2','Scope 3']\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['text_column'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
